{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: BigQuery and SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Solutions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test my sql queries I wrote python scripts to interface directly with the Big Query API.  This permitted me to run a test driven development environment to automate most of the work.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jnapolitano/venvs/finance/lib/python3.9/site-packages/geopandas/_compat.py:111: UserWarning: The Shapely GEOS version (3.10.2-CAPI-1.16.0) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "from pprint import pprint\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] =\"/Users/jnapolitano/.creds/creds.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Big Query Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_big_query(query_string):\n",
    "    client = bigquery.Client()\n",
    "    query_job = client.query(query_string)\n",
    "    results = query_job.result()  # Waits for job to complete.\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "1) Use the publicly available BigQuery dataset named `nyc-tlc.green.trips_2015`, provide SQL queries to answer the following questions:\n",
    "* What is the total amount and passenger counts for the months of February, March and April?\n",
    "* What has been the average hourly passenger count throughout the year?  \n",
    "* What has been the change/delta in total amount billed over days? What we would like see is how much (positive or negative)\n",
    "* What hour of the day has seen the longest rides in April?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.1 \n",
    "* What is the total amount and passenger counts for the months of February, March and April?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion of the Problem\n",
    "\n",
    "I initally approached this problem somewhat naively.  I did not consider the possibliity of taxi rides overlapping per hour.  \n",
    "\n",
    "For example the code below simply considered the pickup_datetime in the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_query_passengers_by_month():\n",
    "    query_string = \"\"\"\n",
    "        SELECT date_trunc(dropoff_datetime,MONTH) as Month,\n",
    "        sum(passenger_count) as Sum_PASS,\n",
    "        sum(total_amount) as TOTAL_AMOUNT_SUM\n",
    "        FROM `nyc-tlc.green.trips_2015` \n",
    "        where dropoff_datetime BETWEEN '2015-02-01' AND '2015-04-30'\n",
    "        GROUP BY Month;\n",
    "        \"\"\"\n",
    "\n",
    "    result = query_big_query(query_string = query_string)\n",
    "\n",
    "    return result.to_dataframe()\n",
    "naive_df = naive_query_passengers_by_month()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Sum_PASS</th>\n",
       "      <th>TOTAL_AMOUNT_SUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-03-01 00:00:00+00:00</td>\n",
       "      <td>2373043</td>\n",
       "      <td>2.512727e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-04-01 00:00:00+00:00</td>\n",
       "      <td>2220040</td>\n",
       "      <td>2.384763e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-02-01 00:00:00+00:00</td>\n",
       "      <td>2170450</td>\n",
       "      <td>2.281705e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Month  Sum_PASS  TOTAL_AMOUNT_SUM\n",
       "0 2015-03-01 00:00:00+00:00   2373043      2.512727e+07\n",
       "1 2015-04-01 00:00:00+00:00   2220040      2.384763e+07\n",
       "2 2015-02-01 00:00:00+00:00   2170450      2.281705e+07"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then attempted to create intervals to unpiviot the table with the following code.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_passenger_total_ammount():\n",
    "\n",
    "    query_string = \"\"\"\n",
    "        #standardSQL\n",
    "        select timestamp_trunc(int, month) month, \n",
    "        count(pickup_datetime) rides,\n",
    "        sum(passenger_count) as passenger_count,\n",
    "        avg(passenger_count) as avg_passenger_count,\n",
    "        sum(total_amount) as total_amount,\n",
    "        avg(total_amount) as avg_total_amount\n",
    "        from `nyc-tlc.green.trips_2015`, \n",
    "        unnest(generate_timestamp_array(\n",
    "        pickup_datetime, \n",
    "        dropoff_datetime, \n",
    "        interval 1 hour)) int\n",
    "        where pickup_datetime BETWEEN '2015-02-01' AND '2015-04-30'\n",
    "        group by month\n",
    "        order by month\n",
    "         \"\"\"\n",
    "    result = query_big_query(query_string)\n",
    "    return result.to_dataframe()\n",
    "\n",
    "df_first_try = total_passenger_total_ammount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>rides</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>avg_passenger_count</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>avg_total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-02-01 00:00:00+00:00</td>\n",
       "      <td>1612934</td>\n",
       "      <td>2226402</td>\n",
       "      <td>1.380343</td>\n",
       "      <td>2.378246e+07</td>\n",
       "      <td>14.744847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-03-01 00:00:00+00:00</td>\n",
       "      <td>1777205</td>\n",
       "      <td>2448797</td>\n",
       "      <td>1.377892</td>\n",
       "      <td>2.647535e+07</td>\n",
       "      <td>14.897184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-04-01 00:00:00+00:00</td>\n",
       "      <td>1667508</td>\n",
       "      <td>2298610</td>\n",
       "      <td>1.378470</td>\n",
       "      <td>2.526557e+07</td>\n",
       "      <td>15.151694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-05-01 00:00:00+00:00</td>\n",
       "      <td>1488</td>\n",
       "      <td>1488</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.803200e+03</td>\n",
       "      <td>3.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-06-01 00:00:00+00:00</td>\n",
       "      <td>1440</td>\n",
       "      <td>1440</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.616000e+03</td>\n",
       "      <td>3.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2020-12-01 00:00:00+00:00</td>\n",
       "      <td>1488</td>\n",
       "      <td>1488</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.803200e+03</td>\n",
       "      <td>3.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2021-01-01 00:00:00+00:00</td>\n",
       "      <td>1488</td>\n",
       "      <td>1488</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.803200e+03</td>\n",
       "      <td>3.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2021-02-01 00:00:00+00:00</td>\n",
       "      <td>1344</td>\n",
       "      <td>1344</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.241600e+03</td>\n",
       "      <td>3.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2021-03-01 00:00:00+00:00</td>\n",
       "      <td>1488</td>\n",
       "      <td>1488</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.803200e+03</td>\n",
       "      <td>3.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2021-04-01 00:00:00+00:00</td>\n",
       "      <td>138</td>\n",
       "      <td>138</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.382000e+02</td>\n",
       "      <td>3.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       month    rides  passenger_count  avg_passenger_count  \\\n",
       "0  2015-02-01 00:00:00+00:00  1612934          2226402             1.380343   \n",
       "1  2015-03-01 00:00:00+00:00  1777205          2448797             1.377892   \n",
       "2  2015-04-01 00:00:00+00:00  1667508          2298610             1.378470   \n",
       "3  2015-05-01 00:00:00+00:00     1488             1488             1.000000   \n",
       "4  2015-06-01 00:00:00+00:00     1440             1440             1.000000   \n",
       "..                       ...      ...              ...                  ...   \n",
       "70 2020-12-01 00:00:00+00:00     1488             1488             1.000000   \n",
       "71 2021-01-01 00:00:00+00:00     1488             1488             1.000000   \n",
       "72 2021-02-01 00:00:00+00:00     1344             1344             1.000000   \n",
       "73 2021-03-01 00:00:00+00:00     1488             1488             1.000000   \n",
       "74 2021-04-01 00:00:00+00:00      138              138             1.000000   \n",
       "\n",
       "    total_amount  avg_total_amount  \n",
       "0   2.378246e+07         14.744847  \n",
       "1   2.647535e+07         14.897184  \n",
       "2   2.526557e+07         15.151694  \n",
       "3   5.803200e+03          3.900000  \n",
       "4   5.616000e+03          3.900000  \n",
       "..           ...               ...  \n",
       "70  5.803200e+03          3.900000  \n",
       "71  5.803200e+03          3.900000  \n",
       "72  5.241600e+03          3.900000  \n",
       "73  5.803200e+03          3.900000  \n",
       "74  5.382000e+02          3.900000  \n",
       "\n",
       "[75 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_first_try"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Problem with this Approach.\n",
    "\n",
    "Firstly the data extends to 2021 for some reason.  There are also negative values within the return set.  I spent a full day tinkering the query to clean the data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_data():\n",
    "\n",
    "  query_string = \"\"\"\n",
    "      SELECT \n",
    "      t.*,\n",
    "      FROM\n",
    "      (\n",
    "      SELECT *,\n",
    "      TIMESTAMP_DIFF(dropoff_datetime,pickup_datetime,SECOND) as time_duration_in_secs,\n",
    "      TIMESTAMP_DIFF(dropoff_datetime,pickup_datetime,MINUTE) as time_duration_in_mins,\n",
    "      ROUND(trip_distance/TIMESTAMP_DIFF(dropoff_datetime,pickup_datetime,SECOND),2)*3600 as driving_speed_miles_per_hour,\n",
    "      (CASE WHEN total_amount=0 THEN 0\n",
    "      ELSE ROUND(tip_amount*100/total_amount,2) END) as tip_rate,\n",
    "      EXTRACT(YEAR from pickup_datetime) as pickup_year,\n",
    "      EXTRACT(MONTH from pickup_datetime) as pickup_month,\n",
    "      CONCAT(CAST(EXTRACT(YEAR from pickup_datetime) as STRING),\"-\",CAST(EXTRACT(MONTH from pickup_datetime) AS STRING)) as pickup_yearmonth,\n",
    "      EXTRACT(DATE from pickup_datetime) as pickup_date,\n",
    "      FORMAT_DATE('%A',DATE(pickup_datetime)) as pickup_weekday_name,\n",
    "      EXTRACT(HOUR from pickup_datetime) as pickup_hour,\n",
    "      EXTRACT(YEAR from dropoff_datetime) as dropoff_year,\n",
    "      EXTRACT(MONTH from dropoff_datetime) as dropoff_month,\n",
    "      CONCAT(CAST(EXTRACT(YEAR from dropoff_datetime) as STRING),\"-\",CAST(EXTRACT(MONTH from dropoff_datetime) AS STRING)) as dropoff_yearmonth,\n",
    "      EXTRACT(DATE from dropoff_datetime) as dropoff_date,\n",
    "      FORMAT_DATE('%A',DATE(dropoff_datetime)) as dropoff_weekday_name,\n",
    "      EXTRACT(HOUR from dropoff_datetime) as dropoff_hour\n",
    "      FROM `nyc-tlc.green.trips_2015`\n",
    "      ) t\n",
    "      WHERE \n",
    "      pickup_datetime BETWEEN '2015-01-01' AND '2016-12-31' \n",
    "      AND dropoff_datetime BETWEEN '2015-01-01' AND '2016-12-31'\n",
    "      AND TIMESTAMP_DIFF(dropoff_datetime,pickup_datetime,SECOND) > 0\n",
    "      AND passenger_count > 0\n",
    "      AND trip_distance >= 0 \n",
    "      AND tip_amount >= 0 \n",
    "      AND tolls_amount >= 0 \n",
    "      AND mta_tax >= 0 \n",
    "      AND fare_amount >= 0\n",
    "      AND total_amount >= 0\n",
    "      order by pickup_date DESC\n",
    "      limit 100000\n",
    "      \"\"\"\n",
    "\n",
    "\n",
    "  result = query_big_query(query_string)\n",
    "      \n",
    "  return result.to_dataframe()\n",
    "\n",
    "clean_df = clean_up_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pickup_datetime', 'dropoff_datetime', 'store_and_fwd_flag',\n",
       "       'rate_code', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude',\n",
       "       'dropoff_latitude', 'passenger_count', 'trip_distance', 'fare_amount',\n",
       "       'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'ehail_fee',\n",
       "       'total_amount', 'payment_type', 'distance_between_service',\n",
       "       'time_between_service', 'trip_type', 'time_duration_in_secs',\n",
       "       'time_duration_in_mins', 'driving_speed_miles_per_hour', 'tip_rate',\n",
       "       'pickup_year', 'pickup_month', 'pickup_yearmonth', 'pickup_date',\n",
       "       'pickup_weekday_name', 'pickup_hour', 'dropoff_year', 'dropoff_month',\n",
       "       'dropoff_yearmonth', 'dropoff_date', 'dropoff_weekday_name',\n",
       "       'dropoff_hour'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion of the Clean Data\n",
    "\n",
    "As we can the see the cleaned data is far more usable.  Typically, I would have performed analysis across a spark cluster or pandas if the resource requirements were not too great. \n",
    "\n",
    "Another approach would have been to export the table to another bigtable instance.   I may experiment with this approach if I have time. \n",
    "\n",
    "\n",
    "For the sake of the problem given to me, I include the table above as a tmp table within the following working queries.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_passenger_total_ammount():\n",
    "\n",
    "    query_string = \"\"\"\n",
    "        #standardSQL\n",
    "        select timestamp_trunc(int, month) month, \n",
    "        count(pickup_datetime) rides,\n",
    "        sum(passenger_count) as passenger_count,\n",
    "        avg(passenger_count) as avg_passenger_count,\n",
    "        sum(total_amount) as total_amount,\n",
    "        avg(total_amount) as avg_total_amount\n",
    "        from `nyc-tlc.green.trips_2015`, \n",
    "        unnest(generate_timestamp_array(\n",
    "        pickup_datetime, \n",
    "        dropoff_datetime, \n",
    "        interval 1 hour)) int\n",
    "        where pickup_datetime BETWEEN '2015-02-01' AND '2015-04-30'\n",
    "        group by month\n",
    "        order by month\n",
    "         \"\"\"\n",
    "\n",
    "    query_string_2 = \"\"\"\n",
    "        with clean as (      \n",
    "            SELECT \n",
    "            t.*,\n",
    "            FROM\n",
    "            (\n",
    "            SELECT *,\n",
    "            TIMESTAMP_DIFF(dropoff_datetime,pickup_datetime,SECOND) as time_duration_in_secs,\n",
    "            TIMESTAMP_DIFF(dropoff_datetime,pickup_datetime,MINUTE) as time_duration_in_mins,\n",
    "            ROUND(trip_distance/TIMESTAMP_DIFF(dropoff_datetime,pickup_datetime,SECOND),2)*3600 as driving_speed_miles_per_hour,\n",
    "            (CASE WHEN total_amount=0 THEN 0\n",
    "            ELSE ROUND(tip_amount*100/total_amount,2) END) as tip_rate,\n",
    "            EXTRACT(YEAR from pickup_datetime) as pickup_year,\n",
    "            EXTRACT(MONTH from pickup_datetime) as pickup_month,\n",
    "            CONCAT(CAST(EXTRACT(YEAR from pickup_datetime) as STRING),\"-\",CAST(EXTRACT(MONTH from pickup_datetime) AS STRING)) as pickup_yearmonth,\n",
    "            EXTRACT(DATE from pickup_datetime) as pickup_date,\n",
    "            FORMAT_DATE('%A',DATE(pickup_datetime)) as pickup_weekday_name,\n",
    "            EXTRACT(HOUR from pickup_datetime) as pickup_hour,\n",
    "            EXTRACT(YEAR from dropoff_datetime) as dropoff_year,\n",
    "            EXTRACT(MONTH from dropoff_datetime) as dropoff_month,\n",
    "            CONCAT(CAST(EXTRACT(YEAR from dropoff_datetime) as STRING),\"-\",CAST(EXTRACT(MONTH from dropoff_datetime) AS STRING)) as dropoff_yearmonth,\n",
    "            EXTRACT(DATE from dropoff_datetime) as dropoff_date,\n",
    "            FORMAT_DATE('%A',DATE(dropoff_datetime)) as dropoff_weekday_name,\n",
    "            EXTRACT(HOUR from dropoff_datetime) as dropoff_hour\n",
    "            FROM `nyc-tlc.green.trips_2015`\n",
    "            /* filter by latitude & longitude that are within the correct range */\n",
    "            WHERE \n",
    "                ((pickup_latitude BETWEEN -90 AND 90) AND\n",
    "                (pickup_longitude BETWEEN -180 AND 180)) \n",
    "            AND\n",
    "                ((dropoff_latitude BETWEEN -90 AND 90) AND\n",
    "                (dropoff_longitude BETWEEN -180 AND 180))\n",
    "            ) t\n",
    "            /* find the boroughs and zone names for dropoff locations */\n",
    "            INNER JOIN `bigquery-public-data.new_york_taxi_trips.taxi_zone_geom` tz_do ON \n",
    "            (ST_DWithin(tz_do.zone_geom,ST_GeogPoint(dropoff_longitude, dropoff_latitude), 0))\n",
    "            /* find the boroughs and zone names for pickup locations */\n",
    "            INNER JOIN `bigquery-public-data.new_york_taxi_trips.taxi_zone_geom` tz_pu ON \n",
    "            (ST_DWithin(tz_pu.zone_geom,ST_GeogPoint(pickup_longitude, pickup_latitude), 0))\n",
    "            WHERE \n",
    "            pickup_datetime BETWEEN '2015-01-01' AND '2016-12-31' \n",
    "            AND dropoff_datetime BETWEEN '2015-01-01' AND '2016-12-31'\n",
    "            AND TIMESTAMP_DIFF(dropoff_datetime,pickup_datetime,SECOND) > 0\n",
    "            AND passenger_count > 0\n",
    "            AND trip_distance >= 0 \n",
    "            AND tip_amount >= 0 \n",
    "            AND tolls_amount >= 0 \n",
    "            AND mta_tax >= 0 \n",
    "            AND fare_amount >= 0\n",
    "            AND total_amount >= 0\n",
    "            )\n",
    "\n",
    "            #standardSQL\n",
    "            select date_trunc(int, MONTH) Month_Datetime,\n",
    "            count(pickup_datetime) rides,\n",
    "            sum(passenger_count) as passenger_count,\n",
    "            avg(passenger_count) as avg_passenger_count,\n",
    "            sum(total_amount) as total_amount,\n",
    "            avg(total_amount) as avg_total_amount\n",
    "            from clean,\n",
    "            unnest(generate_timestamp_array(\n",
    "            pickup_datetime, \n",
    "            dropoff_datetime, \n",
    "            interval 1 hour)) as int\n",
    "            where pickup_datetime BETWEEN '2015-02-01' AND '2015-04-30'\n",
    "            group by Month_Datetime\n",
    "            order by Month_Datetime\n",
    "            \n",
    "        \n",
    "         \"\"\"\n",
    "\n",
    "## In theory the interval could be as small as 1 minute.  Doing so could in theory be more accurate, however, it may also overcount the total ammount billed and the passenger count in the group by.\n",
    "\n",
    "    result = query_big_query(query_string=query_string_2)\n",
    "    df = result.to_dataframe()\n",
    "    return df\n",
    "\n",
    "df = total_passenger_total_ammount()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month_Datetime</th>\n",
       "      <th>rides</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>avg_passenger_count</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>avg_total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-02-01 00:00:00+00:00</td>\n",
       "      <td>1600035</td>\n",
       "      <td>2209835</td>\n",
       "      <td>1.381117</td>\n",
       "      <td>23452447.87</td>\n",
       "      <td>14.657459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-03-01 00:00:00+00:00</td>\n",
       "      <td>1763018</td>\n",
       "      <td>2430562</td>\n",
       "      <td>1.378637</td>\n",
       "      <td>26096490.67</td>\n",
       "      <td>14.802169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-04-01 00:00:00+00:00</td>\n",
       "      <td>1652599</td>\n",
       "      <td>2279631</td>\n",
       "      <td>1.379422</td>\n",
       "      <td>24885815.08</td>\n",
       "      <td>15.058593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Month_Datetime    rides  passenger_count  avg_passenger_count  \\\n",
       "0 2015-02-01 00:00:00+00:00  1600035          2209835             1.381117   \n",
       "1 2015-03-01 00:00:00+00:00  1763018          2430562             1.378637   \n",
       "2 2015-04-01 00:00:00+00:00  1652599          2279631             1.379422   \n",
       "\n",
       "   total_amount  avg_total_amount  \n",
       "0   23452447.87         14.657459  \n",
       "1   26096490.67         14.802169  \n",
       "2   24885815.08         15.058593  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion of the Solution to Problem 1.1\n",
    "\n",
    "The resulting data can is accurate to the month.  It is also account for cases when rides overlap across datetimes.  For example, if a ride begins at 12:00 but ends at 14:00, the query above will count the ridership at hours 12 and 13.   \n",
    "\n",
    "The one drawback to this approach is that it can in theory inflate the total_amount value.  If considering 1 minute intervals as opposed to an hour the rate of hour expands the total_amount value too greatly.  The solution to the problem would be to work with the rate to recalculate the total amount per hour, minute, etc.  Thankfully, as most rides are less than an hour long, it is uncecessary for the question posed.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.2\n",
    "\n",
    "What has been the average hourly passenger count throughout the year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hourly_count_through_year():\n",
    "\n",
    "\n",
    "    query_string_2 = \"\"\"\n",
    "        with clean as (      \n",
    "            SELECT \n",
    "            t.*,\n",
    "            FROM\n",
    "            (\n",
    "            SELECT *,\n",
    "            TIMESTAMP_DIFF(dropoff_datetime,pickup_datetime,SECOND) as time_duration_in_secs,\n",
    "            TIMESTAMP_DIFF(dropoff_datetime,pickup_datetime,MINUTE) as time_duration_in_mins,\n",
    "            ROUND(trip_distance/TIMESTAMP_DIFF(dropoff_datetime,pickup_datetime,SECOND),2)*3600 as driving_speed_miles_per_hour,\n",
    "            (CASE WHEN total_amount=0 THEN 0\n",
    "            ELSE ROUND(tip_amount*100/total_amount,2) END) as tip_rate,\n",
    "            EXTRACT(YEAR from pickup_datetime) as pickup_year,\n",
    "            EXTRACT(MONTH from pickup_datetime) as pickup_month,\n",
    "            CONCAT(CAST(EXTRACT(YEAR from pickup_datetime) as STRING),\"-\",CAST(EXTRACT(MONTH from pickup_datetime) AS STRING)) as pickup_yearmonth,\n",
    "            EXTRACT(DATE from pickup_datetime) as pickup_date,\n",
    "            FORMAT_DATE('%A',DATE(pickup_datetime)) as pickup_weekday_name,\n",
    "            EXTRACT(HOUR from pickup_datetime) as pickup_hour,\n",
    "            EXTRACT(YEAR from dropoff_datetime) as dropoff_year,\n",
    "            EXTRACT(MONTH from dropoff_datetime) as dropoff_month,\n",
    "            CONCAT(CAST(EXTRACT(YEAR from dropoff_datetime) as STRING),\"-\",CAST(EXTRACT(MONTH from dropoff_datetime) AS STRING)) as dropoff_yearmonth,\n",
    "            EXTRACT(DATE from dropoff_datetime) as dropoff_date,\n",
    "            FORMAT_DATE('%A',DATE(dropoff_datetime)) as dropoff_weekday_name,\n",
    "            EXTRACT(HOUR from dropoff_datetime) as dropoff_hour\n",
    "            FROM `nyc-tlc.green.trips_2015`\n",
    "            /* filter by latitude & longitude that are within the correct range */\n",
    "            WHERE \n",
    "                ((pickup_latitude BETWEEN -90 AND 90) AND\n",
    "                (pickup_longitude BETWEEN -180 AND 180)) \n",
    "            AND\n",
    "                ((dropoff_latitude BETWEEN -90 AND 90) AND\n",
    "                (dropoff_longitude BETWEEN -180 AND 180))\n",
    "            ) t\n",
    "            WHERE \n",
    "            pickup_datetime BETWEEN '2015-01-01' AND '2016-12-31' \n",
    "            AND dropoff_datetime BETWEEN '2015-01-01' AND '2016-12-31'\n",
    "            AND passenger_count > 0\n",
    "            AND trip_distance >= 0 \n",
    "            AND tip_amount >= 0 \n",
    "            AND tolls_amount >= 0 \n",
    "            AND mta_tax >= 0 \n",
    "            AND fare_amount >= 0\n",
    "            AND total_amount >= 0\n",
    "            )\n",
    "            #standardSQL\n",
    "            select date_trunc(int, hour) Hour_Datetime,\n",
    "            count(pickup_datetime) rides,\n",
    "            sum(passenger_count) as passenger_count,\n",
    "            avg(passenger_count) as avg_passenger_count,\n",
    "            from clean,\n",
    "            unnest(generate_timestamp_array(\n",
    "            pickup_datetime, \n",
    "            dropoff_datetime, \n",
    "            interval 1 hour)) as int\n",
    "            group by Hour_Datetime\n",
    "            order by Hour_Datetime\n",
    "            \n",
    "            \"\"\"\n",
    "\n",
    "## In theory the interval could be as small as 1 minute.  Doing so could in theory be more accurate, however, it may also overcount the total ammount billed and the passenger count in the group by.\n",
    "\n",
    "    result = query_big_query(query_string=query_string_2)\n",
    "    df = result.to_dataframe()\n",
    "    return df\n",
    "\n",
    "df = hourly_count_through_year()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hour_Datetime</th>\n",
       "      <th>rides</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>avg_passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01 00:00:00+00:00</td>\n",
       "      <td>6458</td>\n",
       "      <td>9605</td>\n",
       "      <td>1.487303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01 01:00:00+00:00</td>\n",
       "      <td>6871</td>\n",
       "      <td>10175</td>\n",
       "      <td>1.480862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01 02:00:00+00:00</td>\n",
       "      <td>6487</td>\n",
       "      <td>9851</td>\n",
       "      <td>1.518576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01 03:00:00+00:00</td>\n",
       "      <td>5913</td>\n",
       "      <td>8822</td>\n",
       "      <td>1.491967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01 04:00:00+00:00</td>\n",
       "      <td>5095</td>\n",
       "      <td>7663</td>\n",
       "      <td>1.504024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4362</th>\n",
       "      <td>2015-07-01 18:00:00+00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4363</th>\n",
       "      <td>2015-07-01 19:00:00+00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4364</th>\n",
       "      <td>2015-07-01 20:00:00+00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4365</th>\n",
       "      <td>2015-07-01 21:00:00+00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4366</th>\n",
       "      <td>2015-07-01 22:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4367 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Hour_Datetime  rides  passenger_count  avg_passenger_count\n",
       "0    2015-01-01 00:00:00+00:00   6458             9605             1.487303\n",
       "1    2015-01-01 01:00:00+00:00   6871            10175             1.480862\n",
       "2    2015-01-01 02:00:00+00:00   6487             9851             1.518576\n",
       "3    2015-01-01 03:00:00+00:00   5913             8822             1.491967\n",
       "4    2015-01-01 04:00:00+00:00   5095             7663             1.504024\n",
       "...                        ...    ...              ...                  ...\n",
       "4362 2015-07-01 18:00:00+00:00      7                8             1.142857\n",
       "4363 2015-07-01 19:00:00+00:00      5                6             1.200000\n",
       "4364 2015-07-01 20:00:00+00:00      5                6             1.200000\n",
       "4365 2015-07-01 21:00:00+00:00      4                5             1.250000\n",
       "4366 2015-07-01 22:00:00+00:00      1                1             1.000000\n",
       "\n",
       "[4367 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion of Question 1.2\n",
    "\n",
    "At first, I was confused why the data terminated at 2015-07-01.  I thought, I had made a mistake. I tested the data on the yellow line data without error.  I then reviewed the big query table to find that it actually terminates at 2015-07-01. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.3\n",
    "\n",
    "* What has been the change/delta in total amount billed over days? What we would like see is how much (positive or negative)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference_by_day():\n",
    "\n",
    "\n",
    "    query_string_2 = \"\"\"\n",
    "        with clean as (      \n",
    "            SELECT \n",
    "            t.*,\n",
    "            FROM\n",
    "            (\n",
    "            SELECT *,\n",
    "            TIMESTAMP_DIFF(dropoff_datetime,pickup_datetime,SECOND) as time_duration_in_secs,\n",
    "            TIMESTAMP_DIFF(dropoff_datetime,pickup_datetime,MINUTE) as time_duration_in_mins,\n",
    "            ROUND(trip_distance/TIMESTAMP_DIFF(dropoff_datetime,pickup_datetime,SECOND),2)*3600 as driving_speed_miles_per_hour,\n",
    "            (CASE WHEN total_amount=0 THEN 0\n",
    "            ELSE ROUND(tip_amount*100/total_amount,2) END) as tip_rate,\n",
    "            EXTRACT(YEAR from pickup_datetime) as pickup_year,\n",
    "            EXTRACT(MONTH from pickup_datetime) as pickup_month,\n",
    "            CONCAT(CAST(EXTRACT(YEAR from pickup_datetime) as STRING),\"-\",CAST(EXTRACT(MONTH from pickup_datetime) AS STRING)) as pickup_yearmonth,\n",
    "            EXTRACT(DATE from pickup_datetime) as pickup_date,\n",
    "            FORMAT_DATE('%A',DATE(pickup_datetime)) as pickup_weekday_name,\n",
    "            EXTRACT(HOUR from pickup_datetime) as pickup_hour,\n",
    "            EXTRACT(YEAR from dropoff_datetime) as dropoff_year,\n",
    "            EXTRACT(MONTH from dropoff_datetime) as dropoff_month,\n",
    "            CONCAT(CAST(EXTRACT(YEAR from dropoff_datetime) as STRING),\"-\",CAST(EXTRACT(MONTH from dropoff_datetime) AS STRING)) as dropoff_yearmonth,\n",
    "            EXTRACT(DATE from dropoff_datetime) as dropoff_date,\n",
    "            FORMAT_DATE('%A',DATE(dropoff_datetime)) as dropoff_weekday_name,\n",
    "            EXTRACT(HOUR from dropoff_datetime) as dropoff_hour\n",
    "            FROM `nyc-tlc.green.trips_2015`\n",
    "            /* filter by latitude & longitude that are within the correct range */\n",
    "            WHERE \n",
    "                ((pickup_latitude BETWEEN -90 AND 90) AND\n",
    "                (pickup_longitude BETWEEN -180 AND 180)) \n",
    "            AND\n",
    "                ((dropoff_latitude BETWEEN -90 AND 90) AND\n",
    "                (dropoff_longitude BETWEEN -180 AND 180))\n",
    "            ) t\n",
    "            /* find the boroughs and zone names for dropoff locations */\n",
    "            INNER JOIN `bigquery-public-data.new_york_taxi_trips.taxi_zone_geom` tz_do ON \n",
    "            (ST_DWithin(tz_do.zone_geom,ST_GeogPoint(dropoff_longitude, dropoff_latitude), 0))\n",
    "            /* find the boroughs and zone names for pickup locations */\n",
    "            INNER JOIN `bigquery-public-data.new_york_taxi_trips.taxi_zone_geom` tz_pu ON \n",
    "            (ST_DWithin(tz_pu.zone_geom,ST_GeogPoint(pickup_longitude, pickup_latitude), 0))\n",
    "            WHERE \n",
    "            pickup_datetime BETWEEN '2015-01-01' AND '2016-12-31' \n",
    "            AND dropoff_datetime BETWEEN '2015-01-01' AND '2016-12-31'\n",
    "            AND TIMESTAMP_DIFF(dropoff_datetime,pickup_datetime,SECOND) > 0\n",
    "            AND passenger_count > 0\n",
    "            AND trip_distance >= 0 \n",
    "            AND tip_amount >= 0 \n",
    "            AND tolls_amount >= 0 \n",
    "            AND mta_tax >= 0 \n",
    "            AND fare_amount >= 0\n",
    "            AND total_amount >= 0\n",
    "            ),\n",
    "            daily as(\n",
    "            #standardSQL\n",
    "            select date_trunc(int, DAY) DAY_Datetime,\n",
    "            count(pickup_datetime) rides,\n",
    "            sum(total_amount) as total_amount,\n",
    "            avg(total_amount) as avg_total_amount\n",
    "            from clean,\n",
    "            unnest(generate_timestamp_array(\n",
    "            pickup_datetime, \n",
    "            dropoff_datetime, \n",
    "            interval 1 hour)) as int\n",
    "            group by DAY_Datetime\n",
    "            order by DAY_Datetime\n",
    "            )\n",
    "\n",
    "            select *,\n",
    "            total_amount - LAG(total_amount) OVER (ORDER BY DAY_Datetime) AS Difference\n",
    "            FROM daily;\n",
    "            \n",
    "        \n",
    "         \"\"\"\n",
    "\n",
    "## In theory the interval could be as small as 1 minute.  Doing so could in theory be more accurate, however, it may also overcount the total ammount billed and the passenger count in the group by.\n",
    "\n",
    "    result = query_big_query(query_string=query_string_2)\n",
    "    df = result.to_dataframe()\n",
    "    return df\n",
    "\n",
    "df = difference_by_day()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAY_Datetime</th>\n",
       "      <th>rides</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>avg_total_amount</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-03-11 00:00:00+00:00</td>\n",
       "      <td>51349</td>\n",
       "      <td>785893.71</td>\n",
       "      <td>15.304947</td>\n",
       "      <td>-12892.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-04-30 00:00:00+00:00</td>\n",
       "      <td>54682</td>\n",
       "      <td>841361.04</td>\n",
       "      <td>15.386435</td>\n",
       "      <td>92337.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-02 00:00:00+00:00</td>\n",
       "      <td>44343</td>\n",
       "      <td>613961.10</td>\n",
       "      <td>13.845728</td>\n",
       "      <td>-349817.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-02-17 00:00:00+00:00</td>\n",
       "      <td>42433</td>\n",
       "      <td>607052.73</td>\n",
       "      <td>14.306147</td>\n",
       "      <td>-61255.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-04-01 00:00:00+00:00</td>\n",
       "      <td>53156</td>\n",
       "      <td>779533.09</td>\n",
       "      <td>14.665007</td>\n",
       "      <td>22250.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>2015-01-15 00:00:00+00:00</td>\n",
       "      <td>48662</td>\n",
       "      <td>703349.06</td>\n",
       "      <td>14.453764</td>\n",
       "      <td>71308.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>2015-02-24 00:00:00+00:00</td>\n",
       "      <td>51009</td>\n",
       "      <td>735429.01</td>\n",
       "      <td>14.417632</td>\n",
       "      <td>-63239.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>2015-03-07 00:00:00+00:00</td>\n",
       "      <td>74557</td>\n",
       "      <td>1113229.81</td>\n",
       "      <td>14.931258</td>\n",
       "      <td>120360.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2015-03-10 00:00:00+00:00</td>\n",
       "      <td>52225</td>\n",
       "      <td>798785.92</td>\n",
       "      <td>15.295087</td>\n",
       "      <td>107550.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>2015-05-29 00:00:00+00:00</td>\n",
       "      <td>62678</td>\n",
       "      <td>980866.89</td>\n",
       "      <td>15.649301</td>\n",
       "      <td>150118.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 DAY_Datetime  rides  total_amount  avg_total_amount  \\\n",
       "0   2015-03-11 00:00:00+00:00  51349     785893.71         15.304947   \n",
       "1   2015-04-30 00:00:00+00:00  54682     841361.04         15.386435   \n",
       "2   2015-01-02 00:00:00+00:00  44343     613961.10         13.845728   \n",
       "3   2015-02-17 00:00:00+00:00  42433     607052.73         14.306147   \n",
       "4   2015-04-01 00:00:00+00:00  53156     779533.09         14.665007   \n",
       "..                        ...    ...           ...               ...   \n",
       "177 2015-01-15 00:00:00+00:00  48662     703349.06         14.453764   \n",
       "178 2015-02-24 00:00:00+00:00  51009     735429.01         14.417632   \n",
       "179 2015-03-07 00:00:00+00:00  74557    1113229.81         14.931258   \n",
       "180 2015-03-10 00:00:00+00:00  52225     798785.92         15.295087   \n",
       "181 2015-05-29 00:00:00+00:00  62678     980866.89         15.649301   \n",
       "\n",
       "     Difference  \n",
       "0     -12892.21  \n",
       "1      92337.70  \n",
       "2    -349817.92  \n",
       "3     -61255.96  \n",
       "4      22250.61  \n",
       "..          ...  \n",
       "177    71308.53  \n",
       "178   -63239.31  \n",
       "179   120360.35  \n",
       "180   107550.57  \n",
       "181   150118.05  \n",
       "\n",
       "[182 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion of Question 1.3\n",
    "\n",
    "The approach is almost identical to my previous answers.  The only major difference is the inclusion of the lag function to determine the running differences.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.4\n",
    "\n",
    "* What hour of the day has seen the longest rides in April?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date_trunc Method\n",
    "\n",
    "Date_trunc will return the requested results per date per hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_rides_per_hour():\n",
    "\n",
    "\n",
    "    query_string_2 = \"\"\"\n",
    "        with clean as (      \n",
    "            SELECT \n",
    "            t.*,\n",
    "            FROM\n",
    "            (\n",
    "            SELECT *,\n",
    "            TIMESTAMP_DIFF(dropoff_datetime,pickup_datetime,SECOND) as time_duration_in_secs,\n",
    "            TIMESTAMP_DIFF(dropoff_datetime,pickup_datetime,MINUTE) as time_duration_in_mins,\n",
    "            ROUND(trip_distance/TIMESTAMP_DIFF(dropoff_datetime,pickup_datetime,SECOND),2)*3600 as driving_speed_miles_per_hour,\n",
    "            (CASE WHEN total_amount=0 THEN 0\n",
    "            ELSE ROUND(tip_amount*100/total_amount,2) END) as tip_rate,\n",
    "            EXTRACT(YEAR from pickup_datetime) as pickup_year,\n",
    "            EXTRACT(MONTH from pickup_datetime) as pickup_month,\n",
    "            CONCAT(CAST(EXTRACT(YEAR from pickup_datetime) as STRING),\"-\",CAST(EXTRACT(MONTH from pickup_datetime) AS STRING)) as pickup_yearmonth,\n",
    "            EXTRACT(DATE from pickup_datetime) as pickup_date,\n",
    "            FORMAT_DATE('%A',DATE(pickup_datetime)) as pickup_weekday_name,\n",
    "            EXTRACT(HOUR from pickup_datetime) as pickup_hour,\n",
    "            EXTRACT(YEAR from dropoff_datetime) as dropoff_year,\n",
    "            EXTRACT(MONTH from dropoff_datetime) as dropoff_month,\n",
    "            CONCAT(CAST(EXTRACT(YEAR from dropoff_datetime) as STRING),\"-\",CAST(EXTRACT(MONTH from dropoff_datetime) AS STRING)) as dropoff_yearmonth,\n",
    "            EXTRACT(DATE from dropoff_datetime) as dropoff_date,\n",
    "            FORMAT_DATE('%A',DATE(dropoff_datetime)) as dropoff_weekday_name,\n",
    "            EXTRACT(HOUR from dropoff_datetime) as dropoff_hour\n",
    "            FROM `nyc-tlc.green.trips_2015`\n",
    "            /* filter by latitude & longitude that are within the correct range */\n",
    "            WHERE \n",
    "                ((pickup_latitude BETWEEN -90 AND 90) AND\n",
    "                (pickup_longitude BETWEEN -180 AND 180)) \n",
    "            AND\n",
    "                ((dropoff_latitude BETWEEN -90 AND 90) AND\n",
    "                (dropoff_longitude BETWEEN -180 AND 180))\n",
    "            ) t\n",
    "            /* find the boroughs and zone names for dropoff locations */\n",
    "            INNER JOIN `bigquery-public-data.new_york_taxi_trips.taxi_zone_geom` tz_do ON \n",
    "            (ST_DWithin(tz_do.zone_geom,ST_GeogPoint(dropoff_longitude, dropoff_latitude), 0))\n",
    "            /* find the boroughs and zone names for pickup locations */\n",
    "            INNER JOIN `bigquery-public-data.new_york_taxi_trips.taxi_zone_geom` tz_pu ON \n",
    "            (ST_DWithin(tz_pu.zone_geom,ST_GeogPoint(pickup_longitude, pickup_latitude), 0))\n",
    "            WHERE \n",
    "            pickup_datetime BETWEEN '2015-01-01' AND '2016-12-31' \n",
    "            AND dropoff_datetime BETWEEN '2015-01-01' AND '2016-12-31'\n",
    "            AND TIMESTAMP_DIFF(dropoff_datetime,pickup_datetime,SECOND) > 0\n",
    "            AND passenger_count > 0\n",
    "            AND trip_distance >= 0 \n",
    "            AND tip_amount >= 0 \n",
    "            AND tolls_amount >= 0 \n",
    "            AND mta_tax >= 0 \n",
    "            AND fare_amount >= 0\n",
    "            AND total_amount >= 0\n",
    "            ),\n",
    "            hourly as(\n",
    "            #standardSQL\n",
    "            select date_trunc(int, hour) DAY_Datetime,\n",
    "            count(pickup_datetime) rides,\n",
    "            sum(total_amount) as total_amount,\n",
    "            avg(total_amount) as avg_total_amount,\n",
    "            avg(time_duration_in_mins) as avg_trip_duration_mins,\n",
    "            max(time_duration_in_mins) as max_time_duration_mins,\n",
    "            avg(trip_distance) as avg_trip_distance,\n",
    "            max(trip_distance) as max_trip_distance\n",
    "            from clean,\n",
    "            unnest(generate_timestamp_array(\n",
    "            pickup_datetime, \n",
    "            dropoff_datetime, \n",
    "            interval 1 hour)) as int\n",
    "            where pickup_datetime BETWEEN '2015-04-01' AND '2015-04-30' \n",
    "            AND dropoff_datetime BETWEEN '2015-04-01' AND '2015-04-30' \n",
    "            group by DAY_Datetime\n",
    "            order by DAY_Datetime\n",
    "            )\n",
    "\n",
    "            select *,\n",
    "            FROM hourly\n",
    "            order by avg_trip_distance DESC, avg_trip_duration_mins DESC;\n",
    "            \n",
    "        \n",
    "         \"\"\"\n",
    "\n",
    "## In theory the interval could be as small as 1 minute.  Doing so could in theory be more accurate, however, it may also overcount the total ammount billed and the passenger count in the group by.\n",
    "\n",
    "    result = query_big_query(query_string=query_string_2)\n",
    "    df = result.to_dataframe()\n",
    "    return df\n",
    "\n",
    "df = longest_rides_per_hour()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAY_Datetime</th>\n",
       "      <th>rides</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>avg_total_amount</th>\n",
       "      <th>avg_trip_duration_mins</th>\n",
       "      <th>max_time_duration_mins</th>\n",
       "      <th>avg_trip_distance</th>\n",
       "      <th>max_trip_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-04-22 05:00:00+00:00</td>\n",
       "      <td>437</td>\n",
       "      <td>8832.02</td>\n",
       "      <td>20.210572</td>\n",
       "      <td>168.228833</td>\n",
       "      <td>1434</td>\n",
       "      <td>4.680458</td>\n",
       "      <td>38.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-04-21 05:00:00+00:00</td>\n",
       "      <td>408</td>\n",
       "      <td>7779.64</td>\n",
       "      <td>19.067745</td>\n",
       "      <td>157.294118</td>\n",
       "      <td>1438</td>\n",
       "      <td>4.563897</td>\n",
       "      <td>22.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-04-08 05:00:00+00:00</td>\n",
       "      <td>417</td>\n",
       "      <td>7911.22</td>\n",
       "      <td>18.971751</td>\n",
       "      <td>178.841727</td>\n",
       "      <td>1439</td>\n",
       "      <td>4.525180</td>\n",
       "      <td>26.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-04-24 05:00:00+00:00</td>\n",
       "      <td>572</td>\n",
       "      <td>11226.31</td>\n",
       "      <td>19.626416</td>\n",
       "      <td>187.965035</td>\n",
       "      <td>1439</td>\n",
       "      <td>4.501678</td>\n",
       "      <td>23.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-04-01 05:00:00+00:00</td>\n",
       "      <td>371</td>\n",
       "      <td>6904.21</td>\n",
       "      <td>18.609730</td>\n",
       "      <td>19.574124</td>\n",
       "      <td>1402</td>\n",
       "      <td>4.483531</td>\n",
       "      <td>21.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>2015-04-07 20:00:00+00:00</td>\n",
       "      <td>3355</td>\n",
       "      <td>43535.74</td>\n",
       "      <td>12.976376</td>\n",
       "      <td>32.518331</td>\n",
       "      <td>1439</td>\n",
       "      <td>2.451830</td>\n",
       "      <td>42.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>2015-04-29 20:00:00+00:00</td>\n",
       "      <td>3599</td>\n",
       "      <td>47430.23</td>\n",
       "      <td>13.178725</td>\n",
       "      <td>16.185051</td>\n",
       "      <td>1438</td>\n",
       "      <td>2.426913</td>\n",
       "      <td>44.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>2015-04-22 18:00:00+00:00</td>\n",
       "      <td>4136</td>\n",
       "      <td>59788.97</td>\n",
       "      <td>14.455747</td>\n",
       "      <td>29.315039</td>\n",
       "      <td>1437</td>\n",
       "      <td>2.410539</td>\n",
       "      <td>60.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>2015-04-07 18:00:00+00:00</td>\n",
       "      <td>3621</td>\n",
       "      <td>50035.31</td>\n",
       "      <td>13.818092</td>\n",
       "      <td>32.520851</td>\n",
       "      <td>1439</td>\n",
       "      <td>2.334471</td>\n",
       "      <td>54.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>2015-04-07 19:00:00+00:00</td>\n",
       "      <td>3954</td>\n",
       "      <td>54699.25</td>\n",
       "      <td>13.833902</td>\n",
       "      <td>29.794133</td>\n",
       "      <td>1439</td>\n",
       "      <td>2.280878</td>\n",
       "      <td>54.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>696 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 DAY_Datetime  rides  total_amount  avg_total_amount  \\\n",
       "0   2015-04-22 05:00:00+00:00    437       8832.02         20.210572   \n",
       "1   2015-04-21 05:00:00+00:00    408       7779.64         19.067745   \n",
       "2   2015-04-08 05:00:00+00:00    417       7911.22         18.971751   \n",
       "3   2015-04-24 05:00:00+00:00    572      11226.31         19.626416   \n",
       "4   2015-04-01 05:00:00+00:00    371       6904.21         18.609730   \n",
       "..                        ...    ...           ...               ...   \n",
       "691 2015-04-07 20:00:00+00:00   3355      43535.74         12.976376   \n",
       "692 2015-04-29 20:00:00+00:00   3599      47430.23         13.178725   \n",
       "693 2015-04-22 18:00:00+00:00   4136      59788.97         14.455747   \n",
       "694 2015-04-07 18:00:00+00:00   3621      50035.31         13.818092   \n",
       "695 2015-04-07 19:00:00+00:00   3954      54699.25         13.833902   \n",
       "\n",
       "     avg_trip_duration_mins  max_time_duration_mins  avg_trip_distance  \\\n",
       "0                168.228833                    1434           4.680458   \n",
       "1                157.294118                    1438           4.563897   \n",
       "2                178.841727                    1439           4.525180   \n",
       "3                187.965035                    1439           4.501678   \n",
       "4                 19.574124                    1402           4.483531   \n",
       "..                      ...                     ...                ...   \n",
       "691               32.518331                    1439           2.451830   \n",
       "692               16.185051                    1438           2.426913   \n",
       "693               29.315039                    1437           2.410539   \n",
       "694               32.520851                    1439           2.334471   \n",
       "695               29.794133                    1439           2.280878   \n",
       "\n",
       "     max_trip_distance  \n",
       "0                38.68  \n",
       "1                22.88  \n",
       "2                26.10  \n",
       "3                23.00  \n",
       "4                21.81  \n",
       "..                 ...  \n",
       "691              42.14  \n",
       "692              44.00  \n",
       "693              60.83  \n",
       "694              54.83  \n",
       "695              54.83  \n",
       "\n",
       "[696 rows x 8 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion of Date Trunc Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wanted to see if avg_trip_duration would correlate with avg_trip_distance.  \n",
    "\n",
    "In this sample it does seem to. I would like to test the distributions later for correlation. \n",
    "\n",
    "To answer the question, 2014-04-22 at 5:00 am recorded the longest trips.  Interestingly, most of longest trips are at 5:00.  I expected the evening rush hour to record a larger number of results. As this is the green line, it would make sense that a large majority of taking the vehicle to the airport or to a determined destination as opposed to randomly hailing a yellow cab.  \n",
    "\n",
    "Review the code below for a results below for a more succint table.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Extract Method\n",
    "\n",
    "Extract will record the values by hour of the 24 hour clock.  It will aggregate accordinly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_rides_per_hour_etracted():\n",
    "\n",
    "\n",
    "    query_string_2 = \"\"\"\n",
    "        with clean as (      \n",
    "            SELECT \n",
    "            t.*,\n",
    "            FROM\n",
    "            (\n",
    "            SELECT *,\n",
    "            TIMESTAMP_DIFF(dropoff_datetime,pickup_datetime,SECOND) as time_duration_in_secs,\n",
    "            TIMESTAMP_DIFF(dropoff_datetime,pickup_datetime,MINUTE) as time_duration_in_mins,\n",
    "            ROUND(trip_distance/TIMESTAMP_DIFF(dropoff_datetime,pickup_datetime,SECOND),2)*3600 as driving_speed_miles_per_hour,\n",
    "            (CASE WHEN total_amount=0 THEN 0\n",
    "            ELSE ROUND(tip_amount*100/total_amount,2) END) as tip_rate,\n",
    "            EXTRACT(YEAR from pickup_datetime) as pickup_year,\n",
    "            EXTRACT(MONTH from pickup_datetime) as pickup_month,\n",
    "            CONCAT(CAST(EXTRACT(YEAR from pickup_datetime) as STRING),\"-\",CAST(EXTRACT(MONTH from pickup_datetime) AS STRING)) as pickup_yearmonth,\n",
    "            EXTRACT(DATE from pickup_datetime) as pickup_date,\n",
    "            FORMAT_DATE('%A',DATE(pickup_datetime)) as pickup_weekday_name,\n",
    "            EXTRACT(HOUR from pickup_datetime) as pickup_hour,\n",
    "            EXTRACT(YEAR from dropoff_datetime) as dropoff_year,\n",
    "            EXTRACT(MONTH from dropoff_datetime) as dropoff_month,\n",
    "            CONCAT(CAST(EXTRACT(YEAR from dropoff_datetime) as STRING),\"-\",CAST(EXTRACT(MONTH from dropoff_datetime) AS STRING)) as dropoff_yearmonth,\n",
    "            EXTRACT(DATE from dropoff_datetime) as dropoff_date,\n",
    "            FORMAT_DATE('%A',DATE(dropoff_datetime)) as dropoff_weekday_name,\n",
    "            EXTRACT(HOUR from dropoff_datetime) as dropoff_hour\n",
    "            FROM `nyc-tlc.green.trips_2015`\n",
    "            /* filter by latitude & longitude that are within the correct range */\n",
    "            WHERE \n",
    "                ((pickup_latitude BETWEEN -90 AND 90) AND\n",
    "                (pickup_longitude BETWEEN -180 AND 180)) \n",
    "            AND\n",
    "                ((dropoff_latitude BETWEEN -90 AND 90) AND\n",
    "                (dropoff_longitude BETWEEN -180 AND 180))\n",
    "            ) t\n",
    "            /* find the boroughs and zone names for dropoff locations */\n",
    "            INNER JOIN `bigquery-public-data.new_york_taxi_trips.taxi_zone_geom` tz_do ON \n",
    "            (ST_DWithin(tz_do.zone_geom,ST_GeogPoint(dropoff_longitude, dropoff_latitude), 0))\n",
    "            /* find the boroughs and zone names for pickup locations */\n",
    "            INNER JOIN `bigquery-public-data.new_york_taxi_trips.taxi_zone_geom` tz_pu ON \n",
    "            (ST_DWithin(tz_pu.zone_geom,ST_GeogPoint(pickup_longitude, pickup_latitude), 0))\n",
    "            WHERE \n",
    "            pickup_datetime BETWEEN '2015-01-01' AND '2016-12-31' \n",
    "            AND dropoff_datetime BETWEEN '2015-01-01' AND '2016-12-31'\n",
    "            AND TIMESTAMP_DIFF(dropoff_datetime,pickup_datetime,SECOND) > 0\n",
    "            AND passenger_count > 0\n",
    "            AND trip_distance >= 0 \n",
    "            AND tip_amount >= 0 \n",
    "            AND tolls_amount >= 0 \n",
    "            AND mta_tax >= 0 \n",
    "            AND fare_amount >= 0\n",
    "            AND total_amount >= 0\n",
    "            ),\n",
    "            hourly as(\n",
    "            #standardSQL\n",
    "            select EXTRACT(HOUR from int) DAY_Datetime,\n",
    "            count(pickup_datetime) rides,\n",
    "            sum(total_amount) as total_amount,\n",
    "            avg(total_amount) as avg_total_amount,\n",
    "            avg(time_duration_in_mins) as avg_trip_duration_mins,\n",
    "            max(time_duration_in_mins) as max_time_duration_mins,\n",
    "            avg(trip_distance) as avg_trip_distance,\n",
    "            max(trip_distance) as max_trip_distance\n",
    "            from clean,\n",
    "            unnest(generate_timestamp_array(\n",
    "            pickup_datetime, \n",
    "            dropoff_datetime, \n",
    "            interval 1 hour)) as int\n",
    "            where pickup_datetime BETWEEN '2015-04-01' AND '2015-04-30' \n",
    "            AND dropoff_datetime BETWEEN '2015-04-01' AND '2015-04-30' \n",
    "            group by DAY_Datetime\n",
    "            order by DAY_Datetime\n",
    "            )\n",
    "\n",
    "            select *,\n",
    "            FROM hourly\n",
    "            order by avg_trip_distance DESC, avg_trip_duration_mins DESC;\n",
    "            \n",
    "        \n",
    "         \"\"\"\n",
    "\n",
    "## In theory the interval could be as small as 1 minute.  Doing so could in theory be more accurate, however, it may also overcount the total ammount billed and the passenger count in the group by.\n",
    "\n",
    "    result = query_big_query(query_string=query_string_2)\n",
    "    df = result.to_dataframe()\n",
    "    return df\n",
    "\n",
    "df = longest_rides_per_hour_etracted()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAY_Datetime</th>\n",
       "      <th>rides</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>avg_total_amount</th>\n",
       "      <th>avg_trip_duration_mins</th>\n",
       "      <th>max_time_duration_mins</th>\n",
       "      <th>avg_trip_distance</th>\n",
       "      <th>max_trip_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>23407</td>\n",
       "      <td>406676.31</td>\n",
       "      <td>17.374132</td>\n",
       "      <td>120.617807</td>\n",
       "      <td>1439</td>\n",
       "      <td>4.013681</td>\n",
       "      <td>58.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>18530</td>\n",
       "      <td>323255.01</td>\n",
       "      <td>17.444955</td>\n",
       "      <td>147.563195</td>\n",
       "      <td>1439</td>\n",
       "      <td>3.994335</td>\n",
       "      <td>87.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>28836</td>\n",
       "      <td>446638.44</td>\n",
       "      <td>15.488918</td>\n",
       "      <td>98.029338</td>\n",
       "      <td>1439</td>\n",
       "      <td>3.406666</td>\n",
       "      <td>87.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>43269</td>\n",
       "      <td>679401.77</td>\n",
       "      <td>15.701814</td>\n",
       "      <td>72.091081</td>\n",
       "      <td>1439</td>\n",
       "      <td>3.254081</td>\n",
       "      <td>70.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>35060</td>\n",
       "      <td>515585.82</td>\n",
       "      <td>14.705813</td>\n",
       "      <td>81.675670</td>\n",
       "      <td>1439</td>\n",
       "      <td>3.136565</td>\n",
       "      <td>87.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23</td>\n",
       "      <td>89991</td>\n",
       "      <td>1347089.17</td>\n",
       "      <td>14.969154</td>\n",
       "      <td>42.006667</td>\n",
       "      <td>1439</td>\n",
       "      <td>3.023357</td>\n",
       "      <td>297.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>67749</td>\n",
       "      <td>1045347.79</td>\n",
       "      <td>15.429715</td>\n",
       "      <td>51.702977</td>\n",
       "      <td>1439</td>\n",
       "      <td>3.018475</td>\n",
       "      <td>70.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>75056</td>\n",
       "      <td>1107289.88</td>\n",
       "      <td>14.752850</td>\n",
       "      <td>44.033082</td>\n",
       "      <td>1439</td>\n",
       "      <td>3.014348</td>\n",
       "      <td>134.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>45003</td>\n",
       "      <td>645698.17</td>\n",
       "      <td>14.347892</td>\n",
       "      <td>65.855010</td>\n",
       "      <td>1439</td>\n",
       "      <td>2.993119</td>\n",
       "      <td>87.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>63888</td>\n",
       "      <td>987487.01</td>\n",
       "      <td>15.456533</td>\n",
       "      <td>54.133186</td>\n",
       "      <td>1439</td>\n",
       "      <td>2.992707</td>\n",
       "      <td>70.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>59383</td>\n",
       "      <td>859156.03</td>\n",
       "      <td>14.468047</td>\n",
       "      <td>52.410690</td>\n",
       "      <td>1439</td>\n",
       "      <td>2.970133</td>\n",
       "      <td>134.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>22</td>\n",
       "      <td>97416</td>\n",
       "      <td>1444937.04</td>\n",
       "      <td>14.832646</td>\n",
       "      <td>39.692453</td>\n",
       "      <td>1439</td>\n",
       "      <td>2.969648</td>\n",
       "      <td>297.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>62846</td>\n",
       "      <td>941869.28</td>\n",
       "      <td>14.986941</td>\n",
       "      <td>54.270678</td>\n",
       "      <td>1439</td>\n",
       "      <td>2.966649</td>\n",
       "      <td>375.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11</td>\n",
       "      <td>61425</td>\n",
       "      <td>922729.92</td>\n",
       "      <td>15.022058</td>\n",
       "      <td>55.576703</td>\n",
       "      <td>1439</td>\n",
       "      <td>2.955951</td>\n",
       "      <td>375.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13</td>\n",
       "      <td>62655</td>\n",
       "      <td>948215.73</td>\n",
       "      <td>15.133920</td>\n",
       "      <td>55.472125</td>\n",
       "      <td>1439</td>\n",
       "      <td>2.954582</td>\n",
       "      <td>375.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12</td>\n",
       "      <td>62336</td>\n",
       "      <td>940571.12</td>\n",
       "      <td>15.088731</td>\n",
       "      <td>55.376476</td>\n",
       "      <td>1439</td>\n",
       "      <td>2.944434</td>\n",
       "      <td>375.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14</td>\n",
       "      <td>71541</td>\n",
       "      <td>1087273.14</td>\n",
       "      <td>15.197902</td>\n",
       "      <td>51.073734</td>\n",
       "      <td>1439</td>\n",
       "      <td>2.923313</td>\n",
       "      <td>375.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>15</td>\n",
       "      <td>80211</td>\n",
       "      <td>1228121.11</td>\n",
       "      <td>15.311131</td>\n",
       "      <td>47.997295</td>\n",
       "      <td>1439</td>\n",
       "      <td>2.896561</td>\n",
       "      <td>375.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>16</td>\n",
       "      <td>86157</td>\n",
       "      <td>1371038.06</td>\n",
       "      <td>15.913252</td>\n",
       "      <td>46.012396</td>\n",
       "      <td>1439</td>\n",
       "      <td>2.860492</td>\n",
       "      <td>375.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>21</td>\n",
       "      <td>99867</td>\n",
       "      <td>1441899.37</td>\n",
       "      <td>14.438197</td>\n",
       "      <td>38.715141</td>\n",
       "      <td>1439</td>\n",
       "      <td>2.824972</td>\n",
       "      <td>297.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>17</td>\n",
       "      <td>96276</td>\n",
       "      <td>1501988.38</td>\n",
       "      <td>15.600860</td>\n",
       "      <td>42.422130</td>\n",
       "      <td>1439</td>\n",
       "      <td>2.747579</td>\n",
       "      <td>375.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20</td>\n",
       "      <td>104678</td>\n",
       "      <td>1482750.27</td>\n",
       "      <td>14.164870</td>\n",
       "      <td>37.491994</td>\n",
       "      <td>1439</td>\n",
       "      <td>2.710590</td>\n",
       "      <td>297.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>19</td>\n",
       "      <td>106840</td>\n",
       "      <td>1557368.06</td>\n",
       "      <td>14.576639</td>\n",
       "      <td>37.460680</td>\n",
       "      <td>1439</td>\n",
       "      <td>2.670077</td>\n",
       "      <td>297.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>18</td>\n",
       "      <td>107685</td>\n",
       "      <td>1609981.95</td>\n",
       "      <td>14.950847</td>\n",
       "      <td>38.261262</td>\n",
       "      <td>1439</td>\n",
       "      <td>2.662435</td>\n",
       "      <td>375.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    DAY_Datetime   rides  total_amount  avg_total_amount  \\\n",
       "0              6   23407     406676.31         17.374132   \n",
       "1              5   18530     323255.01         17.444955   \n",
       "2              4   28836     446638.44         15.488918   \n",
       "3              7   43269     679401.77         15.701814   \n",
       "4              3   35060     515585.82         14.705813   \n",
       "5             23   89991    1347089.17         14.969154   \n",
       "6              9   67749    1045347.79         15.429715   \n",
       "7              0   75056    1107289.88         14.752850   \n",
       "8              2   45003     645698.17         14.347892   \n",
       "9              8   63888     987487.01         15.456533   \n",
       "10             1   59383     859156.03         14.468047   \n",
       "11            22   97416    1444937.04         14.832646   \n",
       "12            10   62846     941869.28         14.986941   \n",
       "13            11   61425     922729.92         15.022058   \n",
       "14            13   62655     948215.73         15.133920   \n",
       "15            12   62336     940571.12         15.088731   \n",
       "16            14   71541    1087273.14         15.197902   \n",
       "17            15   80211    1228121.11         15.311131   \n",
       "18            16   86157    1371038.06         15.913252   \n",
       "19            21   99867    1441899.37         14.438197   \n",
       "20            17   96276    1501988.38         15.600860   \n",
       "21            20  104678    1482750.27         14.164870   \n",
       "22            19  106840    1557368.06         14.576639   \n",
       "23            18  107685    1609981.95         14.950847   \n",
       "\n",
       "    avg_trip_duration_mins  max_time_duration_mins  avg_trip_distance  \\\n",
       "0               120.617807                    1439           4.013681   \n",
       "1               147.563195                    1439           3.994335   \n",
       "2                98.029338                    1439           3.406666   \n",
       "3                72.091081                    1439           3.254081   \n",
       "4                81.675670                    1439           3.136565   \n",
       "5                42.006667                    1439           3.023357   \n",
       "6                51.702977                    1439           3.018475   \n",
       "7                44.033082                    1439           3.014348   \n",
       "8                65.855010                    1439           2.993119   \n",
       "9                54.133186                    1439           2.992707   \n",
       "10               52.410690                    1439           2.970133   \n",
       "11               39.692453                    1439           2.969648   \n",
       "12               54.270678                    1439           2.966649   \n",
       "13               55.576703                    1439           2.955951   \n",
       "14               55.472125                    1439           2.954582   \n",
       "15               55.376476                    1439           2.944434   \n",
       "16               51.073734                    1439           2.923313   \n",
       "17               47.997295                    1439           2.896561   \n",
       "18               46.012396                    1439           2.860492   \n",
       "19               38.715141                    1439           2.824972   \n",
       "20               42.422130                    1439           2.747579   \n",
       "21               37.491994                    1439           2.710590   \n",
       "22               37.460680                    1439           2.670077   \n",
       "23               38.261262                    1439           2.662435   \n",
       "\n",
       "    max_trip_distance  \n",
       "0               58.49  \n",
       "1               87.90  \n",
       "2               87.90  \n",
       "3               70.94  \n",
       "4               87.91  \n",
       "5              297.06  \n",
       "6               70.94  \n",
       "7              134.26  \n",
       "8               87.91  \n",
       "9               70.94  \n",
       "10             134.26  \n",
       "11             297.06  \n",
       "12             375.64  \n",
       "13             375.64  \n",
       "14             375.64  \n",
       "15             375.64  \n",
       "16             375.64  \n",
       "17             375.64  \n",
       "18             375.64  \n",
       "19             297.06  \n",
       "20             375.64  \n",
       "21             297.06  \n",
       "22             297.06  \n",
       "23             375.64  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion of the Extract Method\n",
    "\n",
    "The longest time duration is recorded at 5 am.  The distance between 5 and 6 am are marginal.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}